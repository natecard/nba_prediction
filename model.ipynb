{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import (\n",
    "    DataLoader,\n",
    "    WeightedRandomSampler,\n",
    "    TensorDataset,\n",
    "    random_split,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# change the display width to see all columns\n",
    "pd.set_option(\"display.width\", 500)\n",
    "\n",
    "games_df = pd.read_csv(\"./data/games.csv\", low_memory=False)\n",
    "games_details_df = pd.read_csv(\"./data/games_details.csv\", low_memory=False)\n",
    "# players_df = pd.read_csv('./data/players.csv')\n",
    "ranking_df = pd.read_csv(\"./data/ranking.csv\")\n",
    "teams_df = pd.read_csv(\"./data/teams.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the game dataframe and group by season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107300, 22)\n"
     ]
    }
   ],
   "source": [
    "games_df = games_df.drop(columns=[\"GAME_STATUS_TEXT\"])\n",
    "\n",
    "games_df.groupby([\"SEASON\"])\n",
    "games_df = games_df.sort_values(by=[\"HOME_TEAM_ID\", \"GAME_DATE_EST\"])\n",
    "home_games = games_df[['GAME_ID', 'HOME_TEAM_ID', 'GAME_DATE_EST', 'HOME_TEAM_WINS']].rename(columns={'HOME_TEAM_ID': 'team_id', 'HOME_TEAM_WINS': 'win'})\n",
    "away_games = games_df[['GAME_ID', 'VISITOR_TEAM_ID', 'GAME_DATE_EST', 'HOME_TEAM_WINS']].rename(columns={'VISITOR_TEAM_ID': 'team_id', 'HOME_TEAM_WINS': 'win'})\n",
    "away_games['win'] = 1 - away_games['win']\n",
    "all_games = pd.concat([home_games, away_games]).sort_values(by=['team_id', 'GAME_DATE_EST'])\n",
    "all_games['rolling_wins'] = all_games.groupby('team_id')['win'].rolling(window=10, min_periods=1).sum().reset_index(level=0, drop=True)\n",
    "all_games['prev_10_game_record'] = all_games.groupby('team_id')['rolling_wins'].shift(1)\n",
    "all_games['prev_10_game_record'] = all_games['prev_10_game_record'].fillna(0)\n",
    "home_records = all_games[all_games['GAME_ID'].isin(games_df['GAME_ID']) & (all_games['team_id'].isin(games_df['HOME_TEAM_ID']))]\n",
    "away_records = all_games[all_games['GAME_ID'].isin(games_df['GAME_ID']) & (all_games['team_id'].isin(games_df['VISITOR_TEAM_ID']))]\n",
    "games_df = games_df.merge(home_records[['GAME_ID', 'prev_10_game_record']], left_on='GAME_ID', right_on='GAME_ID', how='left').rename(columns={'prev_10_game_record': 'HOME_TEAM_L10'})\n",
    "games_df = games_df.merge(away_records[['GAME_ID', 'prev_10_game_record']], left_on='GAME_ID', right_on='GAME_ID', how='left').rename(columns={'prev_10_game_record': 'AWAY_TEAM_L10'})\n",
    "\n",
    "print(games_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will create the ELO rating for each team, as a default the team will start with 1500 points. Each time a team wins or loses a game, the ELO rating will be updated. The ELO rating will be updated based on the following formula:\n",
    "\n",
    "\n",
    "\n",
    "Updated Team ELO = Team ELO + k * (Team Expected Outcome - Team Actual Outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_elo = 1500\n",
    "k_factor = 15\n",
    "team_elos = {team_id: initial_elo for team_id in pd.concat([games_df['HOME_TEAM_ID'], games_df['VISITOR_TEAM_ID']]).unique()}\n",
    "\n",
    "\n",
    "def expected_outcome(home_elo, away_elo):\n",
    "    return 1 / (1 + 10 ** ((away_elo - home_elo) / 400))\n",
    "\n",
    "def update_elo(home_elo, visitor_elo, home_win, k_factor):\n",
    "    expected_home_win = expected_outcome(home_elo, visitor_elo)\n",
    "    actual_home_win = 1 if home_win else 0\n",
    "    new_home_elo = home_elo + k_factor * (actual_home_win - expected_home_win)\n",
    "    new_visitor_elo = visitor_elo + k_factor * ((1 - actual_home_win) - (1 - expected_home_win))\n",
    "\n",
    "    return new_home_elo, new_visitor_elo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After iterating, team_elos will have the updated Elo ratings for each team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df = games_df.sort_values('GAME_DATE_EST', ascending=False)\n",
    "games_df['ELO_home'] = 0\n",
    "games_df['ELO_away'] = 0\n",
    "\n",
    "for index, row in games_df.iterrows():\n",
    "    home_team, away_team = row['HOME_TEAM_ID'], row['VISITOR_TEAM_ID']\n",
    "    home_elo, away_elo = team_elos[home_team], team_elos[away_team]\n",
    "    home_win = row['HOME_TEAM_WINS']\n",
    "    new_home_elo, new_away_elo = update_elo(home_elo, away_elo, home_win, k_factor)\n",
    "    games_df.at[index, 'ELO_home'] = round(new_home_elo)\n",
    "    games_df.at[index, 'ELO_away'] = round(new_away_elo)\n",
    "    \n",
    "    team_elos[home_team], team_elos[away_team] = new_home_elo, new_away_elo\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group each Season into its own dataframe, this will help for calculating the overall ELO rating for each team in a season. I can then also track the ELO rating for each team over time, and see how it changes over the course of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAME_DATE_EST      0.000000\n",
      "GAME_ID            0.000000\n",
      "HOME_TEAM_ID       0.000000\n",
      "VISITOR_TEAM_ID    0.000000\n",
      "SEASON             0.000000\n",
      "TEAM_ID_home       0.000000\n",
      "PTS_home           7.148014\n",
      "FG_PCT_home        7.148014\n",
      "FT_PCT_home        7.148014\n",
      "FG3_PCT_home       7.148014\n",
      "AST_home           7.148014\n",
      "REB_home           7.148014\n",
      "TEAM_ID_away       0.000000\n",
      "PTS_away           7.148014\n",
      "FG_PCT_away        7.148014\n",
      "FT_PCT_away        7.148014\n",
      "FG3_PCT_away       7.148014\n",
      "AST_away           7.148014\n",
      "REB_away           7.148014\n",
      "HOME_TEAM_WINS     0.000000\n",
      "HOME_TEAM_L10      0.000000\n",
      "AWAY_TEAM_L10      0.000000\n",
      "ELO_home           0.000000\n",
      "ELO_away           0.000000\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "HOME_TEAM_L10      0.0\n",
      "AWAY_TEAM_L10      0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "HOME_TEAM_L10      0.0\n",
      "AWAY_TEAM_L10      0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "HOME_TEAM_L10      0.0\n",
      "AWAY_TEAM_L10      0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "HOME_TEAM_L10      0.0\n",
      "AWAY_TEAM_L10      0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "HOME_TEAM_L10      0.0\n",
      "AWAY_TEAM_L10      0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "HOME_TEAM_L10      0.0\n",
      "AWAY_TEAM_L10      0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "HOME_TEAM_L10      0.0\n",
      "AWAY_TEAM_L10      0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "HOME_TEAM_L10      0.0\n",
      "AWAY_TEAM_L10      0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "HOME_TEAM_L10      0.0\n",
      "AWAY_TEAM_L10      0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "HOME_TEAM_L10      0.0\n",
      "AWAY_TEAM_L10      0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "HOME_TEAM_L10      0.0\n",
      "AWAY_TEAM_L10      0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "HOME_TEAM_L10      0.0\n",
      "AWAY_TEAM_L10      0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "HOME_TEAM_L10      0.0\n",
      "AWAY_TEAM_L10      0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "HOME_TEAM_L10      0.0\n",
      "AWAY_TEAM_L10      0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "HOME_TEAM_L10      0.0\n",
      "AWAY_TEAM_L10      0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "HOME_TEAM_L10      0.0\n",
      "AWAY_TEAM_L10      0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "HOME_TEAM_L10      0.0\n",
      "AWAY_TEAM_L10      0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "HOME_TEAM_L10      0.0\n",
      "AWAY_TEAM_L10      0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "HOME_TEAM_L10      0.0\n",
      "AWAY_TEAM_L10      0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "seasons_df = games_df.groupby('SEASON')\n",
    "seasons_dict = {}\n",
    "for season, season_df in seasons_df:\n",
    "    seasons_dict[season] = season_df\n",
    "\n",
    "# Iterate over the dictionary and calculate the percentage of missing values\n",
    "for season, season_df in seasons_dict.items():\n",
    "    missing_values_percent = season_df.isnull().sum() * 100 / len(season_df)\n",
    "    # print(f\"Percentage of missing values for season {season}:\")\n",
    "    # print(missing_values_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here each team's ELO will be saved in a dataframe then merged with the team dataframe to get the ELO rating for each team in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_elos_df = pd.DataFrame.from_dict(team_elos, orient=\"index\", columns=[\"ELO\"])\n",
    "team_elos_df = team_elos_df.merge(teams_df, left_index=True, right_on=\"TEAM_ID\")\n",
    "team_elos_df = team_elos_df.sort_values(\"ELO\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of close games: 22764\n",
      "Probability of a close game: 21.293871136720796\n"
     ]
    }
   ],
   "source": [
    "# Create margin of victory column\n",
    "games_df[\"MOV\"] = games_df[\"PTS_home\"] - games_df[\"PTS_away\"]\n",
    "close_games = games_df[(games_df[\"MOV\"] > -5) & (games_df[\"MOV\"] < 5)]\n",
    "print(\"Number of close games:\", close_games.shape[0])\n",
    "\n",
    "close_game_prob = close_games[\"MOV\"].count() / games_df[\"MOV\"].count() * 100\n",
    "print(\"Probability of a close game:\", close_game_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of high scoring games: 25344\n",
      "Probability of a high scoring game: 23.619757688723205\n"
     ]
    }
   ],
   "source": [
    "# Create high scoring game column\n",
    "games_df[\"total_score\"] = games_df[\"PTS_home\"] + games_df[\"PTS_away\"]\n",
    "high_scoring_games = games_df[games_df[\"total_score\"] > 220]\n",
    "print(\"Number of high scoring games:\", high_scoring_games.shape[0])\n",
    "\n",
    "high_scoring_game_prob = len(high_scoring_games) / len(games_df) * 100\n",
    "print(\"Probability of a high scoring game:\", high_scoring_game_prob)\n",
    "\n",
    "games_df = games_df.dropna(ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model each time the model is trained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, losses):\n",
    "    average_loss = round(np.average(losses), 3)\n",
    "    model_to_string = model.__class__.__name__\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    if not os.path.exists(f\"./models/{model_to_string}\"):\n",
    "        os.makedirs(f\"./models/{model_to_string}\")\n",
    "    torch.save(\n",
    "        {\"model_state_dict\": model.state_dict(), \"losses\": losses},\n",
    "        f=f\"./models/{model_to_string}/{average_loss}_on_{timestamp}_model.pth\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(targets, predictions):\n",
    "    predictions_binary = [1 if pred > 0.5 else 0 for pred in predictions]\n",
    "    accuracy = accuracy_score(targets, predictions_binary)\n",
    "    precision = precision_score(targets, predictions_binary, zero_division=0.0)\n",
    "    recall = recall_score(targets, predictions_binary)\n",
    "    f1 = f1_score(targets, predictions_binary)\n",
    "    roc_auc = roc_auc_score(targets, predictions)\n",
    "    conf_matrix = confusion_matrix(targets, predictions_binary)\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"conf_matrix\": conf_matrix\n",
    "    }\n",
    "\n",
    "def print_metrics(phase, metrics):\n",
    "    print(f\"{phase} Accuracy: {metrics['accuracy']}\")\n",
    "    print(f\"{phase} Precision: {metrics['precision']}\")\n",
    "    print(f\"{phase} Recall: {metrics['recall']}\")\n",
    "    print(f\"{phase} F1-Score: {metrics['f1']}\")\n",
    "    print(f\"{phase} ROC-AUC: {metrics['roc_auc']}\")\n",
    "    print(f\"{phase} Confusion Matrix:\\n{metrics['conf_matrix']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class will stop training runs if the training loss is not decreasing anymore. This is done through comparing the current loss with the previous loss. If the loss is not decreasing, the training will stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=25, min_delta=0.01):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_threshold(outputs, threshold=0.5):\n",
    "    return (outputs > threshold).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training function, this function will train the model on the training data and return the model. The model will be trained using the training data and the labels. The model will be trained for a certain number of epochs and the loss will be calculated after each epoch. The loss will be used to determine if the model is improving or not. If the loss is not decreasing, the training will stop.\n",
    "\n",
    "Calculating and printing the metrics for the model, we will use the following metrics: accuracy, precision, recall, f1 score, and confusion matrix. These metrics will help us understand how well the model is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    validation_dataloader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    early_stopping=EarlyStopping(),\n",
    "    num_epochs=100,\n",
    "):\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_targets = []\n",
    "        train_predictions = []\n",
    "\n",
    "        # Training loop\n",
    "        for inputs, targets in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.float()\n",
    "            # Ensure targets are the correct shape\n",
    "            if isinstance(criterion, nn.BCEWithLogitsLoss):\n",
    "                targets = targets.float()\n",
    "            elif isinstance(criterion, nn.CrossEntropyLoss):\n",
    "                targets = targets.float()\n",
    "            elif isinstance(criterion, nn.BCELoss):\n",
    "                targets = targets.float()\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step(loss)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            train_targets.extend(targets.numpy())\n",
    "            train_predictions.extend(outputs.detach().numpy())\n",
    "\n",
    "        train_metrics = calculate_metrics(train_targets, train_predictions)\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "            print_metrics(\"Train\", train_metrics)\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_targets = []\n",
    "        val_predictions = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in validation_dataloader:\n",
    "                outputs = model(inputs)\n",
    "                outputs = outputs.squeeze()\n",
    "\n",
    "                # Ensure targets are the correct shape\n",
    "                if isinstance(criterion, torch.nn.BCEWithLogitsLoss):\n",
    "                    targets = targets.float().view(-1, 1)\n",
    "                elif isinstance(criterion, torch.nn.CrossEntropyLoss):\n",
    "                    targets = targets.long().view(-1)\n",
    "\n",
    "                val_targets.extend(targets.numpy())\n",
    "                val_predictions.extend(outputs.numpy())\n",
    "\n",
    "        val_metrics = calculate_metrics(val_targets, val_predictions)\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print_metrics(\"Validation\", val_metrics)\n",
    "\n",
    "        val_loss = criterion(\n",
    "            torch.tensor(val_predictions), torch.tensor(val_targets).float().squeeze()\n",
    "        ).item()\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    save_model(model, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing function, this function will preprocess the data before training the model. The data will be split into training and testing data. The data will be normalized and the labels will be one-hot encoded. The data will be split into training and testing data using the train_test_split function from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset(labels):\n",
    "    # Calculate the number of samples for each class\n",
    "    class_sample_counts = labels.value_counts().sort_index().tolist()\n",
    "\n",
    "    # Calculate class weights: inverse of the number of samples for each class\n",
    "    class_weights = 1.0 / torch.tensor(class_sample_counts, dtype=torch.float)\n",
    "\n",
    "    # Assign a weight to each sample based on its class\n",
    "    sample_weights = torch.tensor(\n",
    "        [class_weights[label] for label in labels], dtype=torch.float\n",
    "    )\n",
    "\n",
    "    # Create the WeightedRandomSampler\n",
    "    sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
    "\n",
    "    return sampler\n",
    "\n",
    "\n",
    "def smote_fn(features_df, games_df):\n",
    "    # Split the data\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        features_df,\n",
    "        games_df[\"HOME_TEAM_WINS\"],\n",
    "        test_size=0.2,\n",
    "        stratify=games_df[\"HOME_TEAM_WINS\"],\n",
    "    )\n",
    "\n",
    "    # Apply SMOTE\n",
    "    smote = SMOTE()\n",
    "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Convert to tensors\n",
    "    features = torch.tensor(X_train_res.values, dtype=torch.float32)\n",
    "    labels = torch.tensor(y_train_res.values, dtype=torch.long).view(-1, 1)\n",
    "\n",
    "    return features, labels, X_val, y_val\n",
    "\n",
    "\n",
    "def prepare_data(games_df):\n",
    "    # Select relevant features\n",
    "    features_df = games_df[\n",
    "        [\n",
    "            \"SEASON\",\n",
    "            \"total_score\",\n",
    "            \"ELO_home\",\n",
    "            \"ELO_away\",\n",
    "            \"HOME_TEAM_ID\",\n",
    "            \"VISITOR_TEAM_ID\",\n",
    "            \"HOME_TEAM_L10\",\n",
    "            \"AWAY_TEAM_L10\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Apply SMOTE and split data\n",
    "    features, labels, X_val, y_val = smote_fn(features_df, games_df)\n",
    "    dataset = TensorDataset(features, labels)\n",
    "\n",
    "    # Split dataset into training and test sets\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    # Extract labels from the train dataset for balancing\n",
    "    train_labels = pd.Series([label.item() for _, label in train_dataset])\n",
    "    sampler = balance_dataset(train_labels)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=128, sampler=sampler)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "    # Create DataLoader for validation set\n",
    "    val_features = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "    val_labels = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1)\n",
    "    val_dataset = TensorDataset(val_features, val_labels)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "    return train_dataloader, test_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Model Creation\n",
    "\n",
    "The model is created, experimenting with the different model architecture. The model will be trained on the first 80% of the data, and tested on the last 20% of the data. The model will be evaluated based on the accuracy of the predictions. \n",
    "\n",
    "The model will be trained on the ELO rating of each team, and the difference in ELO rating between the two teams. The model will predict the outcome of the game based on the ELO rating of each team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 36.16071319580078\n",
      "Train Accuracy: 0.5020465370113117\n",
      "Train Precision: 0.5020465370113117\n",
      "Train Recall: 1.0\n",
      "Train F1-Score: 0.6684833320946978\n",
      "Train ROC-AUC: 0.5\n",
      "Train Confusion Matrix:\n",
      "[[    0 40147]\n",
      " [    0 40477]]\n",
      "Validation Accuracy: 0.5892147233525092\n",
      "Validation Precision: 0.5892147233525092\n",
      "Validation Recall: 1.0\n",
      "Validation F1-Score: 0.7415168192118662\n",
      "Validation ROC-AUC: 0.5\n",
      "Validation Confusion Matrix:\n",
      "[[    0  8783]\n",
      " [    0 12598]]\n",
      "Epoch 10, Loss: 44.19643020629883\n",
      "Train Accuracy: 0.5025550704504862\n",
      "Train Precision: 0.5025550704504862\n",
      "Train Recall: 1.0\n",
      "Train F1-Score: 0.6689339783064503\n",
      "Train ROC-AUC: 0.5\n",
      "Train Confusion Matrix:\n",
      "[[    0 40106]\n",
      " [    0 40518]]\n",
      "Validation Accuracy: 0.5892147233525092\n",
      "Validation Precision: 0.5892147233525092\n",
      "Validation Recall: 1.0\n",
      "Validation F1-Score: 0.7415168192118662\n",
      "Validation ROC-AUC: 0.5\n",
      "Validation Confusion Matrix:\n",
      "[[    0  8783]\n",
      " [    0 12598]]\n",
      "Epoch 15, Loss: 36.16071319580078\n",
      "Train Accuracy: 0.503448104782695\n",
      "Train Precision: 0.503448104782695\n",
      "Train Recall: 1.0\n",
      "Train F1-Score: 0.6697246192684013\n",
      "Train ROC-AUC: 0.5\n",
      "Train Confusion Matrix:\n",
      "[[    0 40034]\n",
      " [    0 40590]]\n",
      "Validation Accuracy: 0.5892147233525092\n",
      "Validation Precision: 0.5892147233525092\n",
      "Validation Recall: 1.0\n",
      "Validation F1-Score: 0.7415168192118662\n",
      "Validation ROC-AUC: 0.5\n",
      "Validation Confusion Matrix:\n",
      "[[    0  8783]\n",
      " [    0 12598]]\n",
      "Epoch 20, Loss: 36.83035659790039\n",
      "Train Accuracy: 0.5022697955943639\n",
      "Train Precision: 0.5022697955943639\n",
      "Train Recall: 1.0\n",
      "Train F1-Score: 0.6686812143429189\n",
      "Train ROC-AUC: 0.5\n",
      "Train Confusion Matrix:\n",
      "[[    0 40129]\n",
      " [    0 40495]]\n",
      "Validation Accuracy: 0.5892147233525092\n",
      "Validation Precision: 0.5892147233525092\n",
      "Validation Recall: 1.0\n",
      "Validation F1-Score: 0.7415168192118662\n",
      "Validation ROC-AUC: 0.5\n",
      "Validation Confusion Matrix:\n",
      "[[    0  8783]\n",
      " [    0 12598]]\n",
      "Epoch 25, Loss: 33.48214340209961\n",
      "Train Accuracy: 0.5006697757491566\n",
      "Train Precision: 0.5006697757491566\n",
      "Train Recall: 1.0\n",
      "Train F1-Score: 0.667261757170014\n",
      "Train ROC-AUC: 0.5\n",
      "Train Confusion Matrix:\n",
      "[[    0 40258]\n",
      " [    0 40366]]\n",
      "Validation Accuracy: 0.5892147233525092\n",
      "Validation Precision: 0.5892147233525092\n",
      "Validation Recall: 1.0\n",
      "Validation F1-Score: 0.7415168192118662\n",
      "Validation ROC-AUC: 0.5\n",
      "Validation Confusion Matrix:\n",
      "[[    0  8783]\n",
      " [    0 12598]]\n",
      "Early stopping at epoch 26\n"
     ]
    }
   ],
   "source": [
    "skip_cell = False\n",
    "\n",
    "if not skip_cell:\n",
    "\n",
    "    class BinaryClassifier(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(BinaryClassifier, self).__init__()\n",
    "            self.fc1 = nn.Linear(in_features=8, out_features=50)\n",
    "            self.fc2 = nn.Linear(50, 1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.prelu(self.fc1(x), torch.tensor(0.75))\n",
    "            x = torch.sigmoid(self.fc2(x))\n",
    "            return x\n",
    "\n",
    "    train_dataloader, test_dataloader, validation_dataloader = prepare_data(games_df)\n",
    "    model = BinaryClassifier()\n",
    "    criterion = nn.BCELoss(weight=torch.tensor(0.75))\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \"min\", cooldown=5, patience=2\n",
    "    )\n",
    "\n",
    "    train_model(\n",
    "        model,\n",
    "        train_dataloader,\n",
    "        test_dataloader,\n",
    "        validation_dataloader,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        EarlyStopping(),\n",
    "        num_epochs=200,\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(\"Cell skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model v2 - relu activation function and larger hidden layers\n",
    "Here I have created a model with larger hidden layers, and more hidden layers, to see if the model can learn more complex patterns in the data. The learning rate is lowered and a scheduler is added to help the model converge to a better solution. The model is trained for 100 epochs, and the loss rate is assessed to see if the model is learning at a better rate than the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 30.803571701049805\n",
      "Train Accuracy: 0.49939224052391346\n",
      "Train Precision: 0.0\n",
      "Train Recall: 0.0\n",
      "Train F1-Score: 0.0\n",
      "Train ROC-AUC: 0.5\n",
      "Train Confusion Matrix:\n",
      "[[40263     0]\n",
      " [40361     0]]\n",
      "Validation Accuracy: 0.41078527664749076\n",
      "Validation Precision: 0.0\n",
      "Validation Recall: 0.0\n",
      "Validation F1-Score: 0.0\n",
      "Validation ROC-AUC: 0.5\n",
      "Validation Confusion Matrix:\n",
      "[[ 8783     0]\n",
      " [12598     0]]\n",
      "Epoch 10, Loss: 34.82143020629883\n",
      "Train Accuracy: 0.5004837269299465\n",
      "Train Precision: 0.0\n",
      "Train Recall: 0.0\n",
      "Train F1-Score: 0.0\n",
      "Train ROC-AUC: 0.5\n",
      "Train Confusion Matrix:\n",
      "[[40351     0]\n",
      " [40273     0]]\n",
      "Validation Accuracy: 0.41078527664749076\n",
      "Validation Precision: 0.0\n",
      "Validation Recall: 0.0\n",
      "Validation F1-Score: 0.0\n",
      "Validation ROC-AUC: 0.5\n",
      "Validation Confusion Matrix:\n",
      "[[ 8783     0]\n",
      " [12598     0]]\n",
      "Epoch 15, Loss: 41.51785659790039\n",
      "Train Accuracy: 0.49880928755705495\n",
      "Train Precision: 0.0\n",
      "Train Recall: 0.0\n",
      "Train F1-Score: 0.0\n",
      "Train ROC-AUC: 0.5\n",
      "Train Confusion Matrix:\n",
      "[[40216     0]\n",
      " [40408     0]]\n",
      "Validation Accuracy: 0.41078527664749076\n",
      "Validation Precision: 0.0\n",
      "Validation Recall: 0.0\n",
      "Validation F1-Score: 0.0\n",
      "Validation ROC-AUC: 0.5\n",
      "Validation Confusion Matrix:\n",
      "[[ 8783     0]\n",
      " [12598     0]]\n",
      "Epoch 20, Loss: 34.82143020629883\n",
      "Train Accuracy: 0.4974449295495138\n",
      "Train Precision: 0.0\n",
      "Train Recall: 0.0\n",
      "Train F1-Score: 0.0\n",
      "Train ROC-AUC: 0.5\n",
      "Train Confusion Matrix:\n",
      "[[40106     0]\n",
      " [40518     0]]\n",
      "Validation Accuracy: 0.41078527664749076\n",
      "Validation Precision: 0.0\n",
      "Validation Recall: 0.0\n",
      "Validation F1-Score: 0.0\n",
      "Validation ROC-AUC: 0.5\n",
      "Validation Confusion Matrix:\n",
      "[[ 8783     0]\n",
      " [12598     0]]\n",
      "Epoch 25, Loss: 37.5\n",
      "Train Accuracy: 0.5017488589005755\n",
      "Train Precision: 0.0\n",
      "Train Recall: 0.0\n",
      "Train F1-Score: 0.0\n",
      "Train ROC-AUC: 0.5\n",
      "Train Confusion Matrix:\n",
      "[[40453     0]\n",
      " [40171     0]]\n",
      "Validation Accuracy: 0.41078527664749076\n",
      "Validation Precision: 0.0\n",
      "Validation Recall: 0.0\n",
      "Validation F1-Score: 0.0\n",
      "Validation ROC-AUC: 0.5\n",
      "Validation Confusion Matrix:\n",
      "[[ 8783     0]\n",
      " [12598     0]]\n",
      "Early stopping at epoch 26\n"
     ]
    }
   ],
   "source": [
    "skip_cell = False\n",
    "if not skip_cell:\n",
    "\n",
    "    class BinaryClassifierV2(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(BinaryClassifierV2, self).__init__()\n",
    "            self.fc1 = nn.Linear(in_features=8, out_features=1000)\n",
    "            self.fc2 = nn.Linear(1000, 50)\n",
    "            self.fc3 = nn.Linear(50, 1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = torch.sigmoid(self.fc3(x))\n",
    "            return x\n",
    "\n",
    "    model = BinaryClassifierV2()\n",
    "    train_dataloader, test_dataloader, validation_dataloader = prepare_data(games_df)\n",
    "    criterion = nn.BCELoss(weight=torch.tensor(0.75))\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \"min\", cooldown=5, patience=2\n",
    "    )\n",
    "    train_model(\n",
    "        model,\n",
    "        train_dataloader,\n",
    "        test_dataloader,\n",
    "        validation_dataloader,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        EarlyStopping(),\n",
    "        num_epochs=200,\n",
    "    )\n",
    "else:\n",
    "    print(\"Cell skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model v3.1 - More model information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 32.8125\n",
      "Train Accuracy: 0.5004713236753324\n",
      "Train Precision: 0.5004713236753324\n",
      "Train Recall: 1.0\n",
      "Train F1-Score: 0.6670854894440128\n",
      "Train ROC-AUC: 0.5\n",
      "Train Confusion Matrix:\n",
      "[[    0 40274]\n",
      " [    0 40350]]\n",
      "Validation Accuracy: 0.5892147233525092\n",
      "Validation Precision: 0.5892147233525092\n",
      "Validation Recall: 1.0\n",
      "Validation F1-Score: 0.7415168192118662\n",
      "Validation ROC-AUC: 0.5\n",
      "Validation Confusion Matrix:\n",
      "[[    0  8783]\n",
      " [    0 12598]]\n",
      "Epoch 10, Loss: 35.49106979370117\n",
      "Train Accuracy: 0.49748213931335583\n",
      "Train Precision: 0.49748213931335583\n",
      "Train Recall: 1.0\n",
      "Train F1-Score: 0.664424805148551\n",
      "Train ROC-AUC: 0.5\n",
      "Train Confusion Matrix:\n",
      "[[    0 40515]\n",
      " [    0 40109]]\n",
      "Validation Accuracy: 0.5892147233525092\n",
      "Validation Precision: 0.5892147233525092\n",
      "Validation Recall: 1.0\n",
      "Validation F1-Score: 0.7415168192118662\n",
      "Validation ROC-AUC: 0.5\n",
      "Validation Confusion Matrix:\n",
      "[[    0  8783]\n",
      " [    0 12598]]\n",
      "Epoch 15, Loss: 34.15178680419922\n",
      "Train Accuracy: 0.4998511609446319\n",
      "Train Precision: 0.4998511609446319\n",
      "Train Recall: 1.0\n",
      "Train F1-Score: 0.6665343521550726\n",
      "Train ROC-AUC: 0.5\n",
      "Train Confusion Matrix:\n",
      "[[    0 40324]\n",
      " [    0 40300]]\n",
      "Validation Accuracy: 0.5892147233525092\n",
      "Validation Precision: 0.5892147233525092\n",
      "Validation Recall: 1.0\n",
      "Validation F1-Score: 0.7415168192118662\n",
      "Validation ROC-AUC: 0.5\n",
      "Validation Confusion Matrix:\n",
      "[[    0  8783]\n",
      " [    0 12598]]\n",
      "Epoch 20, Loss: 38.16964340209961\n",
      "Train Accuracy: 0.5008186148045247\n",
      "Train Precision: 0.5008186148045247\n",
      "Train Recall: 1.0\n",
      "Train F1-Score: 0.6673939273731012\n",
      "Train ROC-AUC: 0.5\n",
      "Train Confusion Matrix:\n",
      "[[    0 40246]\n",
      " [    0 40378]]\n",
      "Validation Accuracy: 0.5892147233525092\n",
      "Validation Precision: 0.5892147233525092\n",
      "Validation Recall: 1.0\n",
      "Validation F1-Score: 0.7415168192118662\n",
      "Validation ROC-AUC: 0.5\n",
      "Validation Confusion Matrix:\n",
      "[[    0  8783]\n",
      " [    0 12598]]\n",
      "Epoch 25, Loss: 35.49106979370117\n",
      "Train Accuracy: 0.49831315737249454\n",
      "Train Precision: 0.49831315737249454\n",
      "Train Recall: 1.0\n",
      "Train F1-Score: 0.6651655629139073\n",
      "Train ROC-AUC: 0.5\n",
      "Train Confusion Matrix:\n",
      "[[    0 40448]\n",
      " [    0 40176]]\n",
      "Validation Accuracy: 0.5892147233525092\n",
      "Validation Precision: 0.5892147233525092\n",
      "Validation Recall: 1.0\n",
      "Validation F1-Score: 0.7415168192118662\n",
      "Validation ROC-AUC: 0.5\n",
      "Validation Confusion Matrix:\n",
      "[[    0  8783]\n",
      " [    0 12598]]\n",
      "Early stopping at epoch 26\n"
     ]
    }
   ],
   "source": [
    "skip_cell = False\n",
    "if not skip_cell:\n",
    "\n",
    "    class BinaryClassifierV3(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(BinaryClassifierV3, self).__init__()\n",
    "            self.fc1 = nn.Linear(in_features=8, out_features=1000)\n",
    "            self.fc2 = nn.Linear(1000, 50)\n",
    "            self.fc3 = nn.Linear(50, 1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = torch.sigmoid(self.fc3(x))\n",
    "            return x\n",
    "\n",
    "    model = BinaryClassifierV3()\n",
    "    train_dataloader, test_dataloader, validation_dataloader = prepare_data(games_df)\n",
    "    criterion = nn.BCELoss(weight=torch.tensor(0.75))\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \"min\", cooldown=5, patience=2\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \"min\", cooldown=5, patience=2\n",
    "    )\n",
    "\n",
    "    train_model(\n",
    "        model,\n",
    "        train_dataloader,\n",
    "        test_dataloader,\n",
    "        validation_dataloader,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        EarlyStopping(),\n",
    "        num_epochs=200,\n",
    "    )\n",
    "else:\n",
    "    print(\"Cell skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Model - Adding Dropout Layers\n",
    "\n",
    "Here I have added dropout layers to the model to help prevent overfitting. The dropout rate is set to 0.5, increasing layer count to 7 and increasing the number of neurons in each layer. The model is evaluated based on the loss rate, and the accuracy of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell skipped\n"
     ]
    }
   ],
   "source": [
    "skip_cell = True\n",
    "if not skip_cell:\n",
    "    class BinaryClassifierDropout(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(BinaryClassifierDropout, self).__init__()\n",
    "            self.fc1 = nn.Linear(in_features=8, out_features=1000)\n",
    "            self.dropout1 = nn.Dropout(p=0.5)\n",
    "            self.fc2 = nn.Linear(1000, 1000)\n",
    "            self.dropout2 = nn.Dropout(p=0.5)\n",
    "            self.fc3 = nn.Linear(1000, 1000)\n",
    "            self.dropout3 = nn.Dropout(p=0.5)\n",
    "            self.fc4 = nn.Linear(1000, 1000)\n",
    "            self.dropout4 = nn.Dropout(p=0.5)\n",
    "            self.fc5 = nn.Linear(1000, 1000)\n",
    "            self.dropout5 = nn.Dropout(p=0.5)\n",
    "            self.fc6 = nn.Linear(1000, 500)\n",
    "            self.dropout6 = nn.Dropout(p=0.5)\n",
    "            self.fc7 = nn.Linear(500, 1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = self.dropout1(x)\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.dropout2(x)\n",
    "            x = F.relu(self.fc3(x))\n",
    "            x = self.dropout3(x)\n",
    "            x = F.relu(self.fc4(x))\n",
    "            x = self.dropout4(x)\n",
    "            x = F.relu(self.fc5(x))\n",
    "            x = self.dropout5(x)\n",
    "            x = F.relu(self.fc6(x))\n",
    "            x = self.dropout6(x)\n",
    "            x = torch.sigmoid(self.fc7(x))\n",
    "            return x\n",
    "    train_dataloader, test_dataloader, validation_dataloader = prepare_data(games_df)\n",
    "    class_weights = [1.0, 1.0]\n",
    "    model = BinaryClassifierDropout()\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([class_weights[1]]))\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', cooldown=5, patience=2)\n",
    "\n",
    "    train_model(\n",
    "        model,\n",
    "        train_dataloader,\n",
    "        test_dataloader,\n",
    "        validation_dataloader,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        EarlyStopping(),\n",
    "        num_epochs=200,\n",
    "    )\n",
    "else:\n",
    "    print(\"Cell skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth Model - Adding Batch Normalization \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell skipped\n"
     ]
    }
   ],
   "source": [
    "skip_cell = True\n",
    "\n",
    "if not skip_cell:\n",
    "\n",
    "    class BinaryClassifierDropout(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(BinaryClassifierDropout, self).__init__()\n",
    "            self.fc1 = nn.Linear(in_features=8, out_features=1000)\n",
    "            self.dropout1 = nn.Dropout(p=0.5)\n",
    "            self.fc2 = nn.Linear(1000, 500)\n",
    "            self.dropout2 = nn.Dropout(p=0.2)\n",
    "            self.fc3 = nn.Linear(500, 500)\n",
    "            self.dropout3 = nn.Dropout(p=0.5)\n",
    "            self.fc4 = nn.Linear(500, 500)\n",
    "            self.dropout4 = nn.Dropout(p=0.7)\n",
    "            self.fc5 = nn.Linear(500, 500)\n",
    "            self.dropout5 = nn.Dropout(p=0.2)\n",
    "            self.fc6 = nn.Linear(500, 500)\n",
    "            self.dropout6 = nn.Dropout(p=0.5)\n",
    "            self.fc7 = nn.Linear(500, 1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.leaky_relu(self.fc1(x))\n",
    "            x = self.dropout1(x)\n",
    "            x = F.leaky_relu(self.fc2(x))\n",
    "            x = self.dropout2(x)\n",
    "            x = F.leaky_relu(self.fc3(x))\n",
    "            x = self.dropout3(x)\n",
    "            x = F.leaky_relu(self.fc4(x))\n",
    "            x = self.dropout4(x)\n",
    "            x = F.leaky_relu(self.fc5(x))\n",
    "            x = self.dropout5(x)\n",
    "            x = F.leaky_relu(self.fc6(x))\n",
    "            x = self.dropout6(x)\n",
    "            x = torch.sigmoid(self.fc7(x))\n",
    "            return x\n",
    "\n",
    "    model = BinaryClassifierDropout()\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([class_weights[1]]))\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \"min\", cooldown=5, patience=2\n",
    "    )\n",
    "\n",
    "    train_model(\n",
    "        model,\n",
    "        train_dataloader,\n",
    "        test_dataloader,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        EarlyStopping(),\n",
    "        num_epochs=200,\n",
    "    )\n",
    "else:\n",
    "    print(\"Cell skipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.7329044938087463\n",
      "Train Accuracy: 0.4997519349077198\n",
      "Train Precision: 0.4997519349077198\n",
      "Train Recall: 1.0\n",
      "Train F1-Score: 0.6664461278904363\n",
      "Train ROC-AUC: 0.5\n",
      "Train Confusion Matrix:\n",
      "[[    0 40332]\n",
      " [    0 40292]]\n",
      "Validation Accuracy: 0.5892147233525092\n",
      "Validation Precision: 0.5892147233525092\n",
      "Validation Recall: 1.0\n",
      "Validation F1-Score: 0.7415168192118662\n",
      "Validation ROC-AUC: 0.5\n",
      "Validation Confusion Matrix:\n",
      "[[    0  8783]\n",
      " [    0 12598]]\n",
      "Epoch 10, Loss: 0.8043331503868103\n",
      "Train Accuracy: 0.5008062115499107\n",
      "Train Precision: 0.5008062115499107\n",
      "Train Recall: 1.0\n",
      "Train F1-Score: 0.6673829141907918\n",
      "Train ROC-AUC: 0.5\n",
      "Train Confusion Matrix:\n",
      "[[    0 40247]\n",
      " [    0 40377]]\n",
      "Validation Accuracy: 0.5892147233525092\n",
      "Validation Precision: 0.5892147233525092\n",
      "Validation Recall: 1.0\n",
      "Validation F1-Score: 0.7415168192118662\n",
      "Validation ROC-AUC: 0.5\n",
      "Validation Confusion Matrix:\n",
      "[[    0  8783]\n",
      " [    0 12598]]\n",
      "Epoch 15, Loss: 0.7864760160446167\n",
      "Train Accuracy: 0.5001240325461401\n",
      "Train Precision: 0.5001240325461401\n",
      "Train Recall: 1.0\n",
      "Train F1-Score: 0.6667769087030576\n",
      "Train ROC-AUC: 0.5\n",
      "Train Confusion Matrix:\n",
      "[[    0 40302]\n",
      " [    0 40322]]\n",
      "Validation Accuracy: 0.5892147233525092\n",
      "Validation Precision: 0.5892147233525092\n",
      "Validation Recall: 1.0\n",
      "Validation F1-Score: 0.7415168192118662\n",
      "Validation ROC-AUC: 0.5\n",
      "Validation Confusion Matrix:\n",
      "[[    0  8783]\n",
      " [    0 12598]]\n",
      "Epoch 20, Loss: 0.9025474190711975\n",
      "Train Accuracy: 0.49841238340940663\n",
      "Train Precision: 0.49841238340940663\n",
      "Train Recall: 1.0\n",
      "Train F1-Score: 0.6652539566916099\n",
      "Train ROC-AUC: 0.5\n",
      "Train Confusion Matrix:\n",
      "[[    0 40440]\n",
      " [    0 40184]]\n",
      "Validation Accuracy: 0.5892147233525092\n",
      "Validation Precision: 0.5892147233525092\n",
      "Validation Recall: 1.0\n",
      "Validation F1-Score: 0.7415168192118662\n",
      "Validation ROC-AUC: 0.5\n",
      "Validation Confusion Matrix:\n",
      "[[    0  8783]\n",
      " [    0 12598]]\n",
      "Epoch 25, Loss: 0.8132616877555847\n",
      "Train Accuracy: 0.4948526493351856\n",
      "Train Precision: 0.4948526493351856\n",
      "Train Recall: 1.0\n",
      "Train F1-Score: 0.6620754889189436\n",
      "Train ROC-AUC: 0.5\n",
      "Train Confusion Matrix:\n",
      "[[    0 40727]\n",
      " [    0 39897]]\n",
      "Validation Accuracy: 0.5892147233525092\n",
      "Validation Precision: 0.5892147233525092\n",
      "Validation Recall: 1.0\n",
      "Validation F1-Score: 0.7415168192118662\n",
      "Validation ROC-AUC: 0.5\n",
      "Validation Confusion Matrix:\n",
      "[[    0  8783]\n",
      " [    0 12598]]\n",
      "Early stopping at epoch 26\n"
     ]
    }
   ],
   "source": [
    "skip_cell = False\n",
    "\n",
    "if not skip_cell:\n",
    "\n",
    "    class BinaryClassifierDropout(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(BinaryClassifierDropout, self).__init__()\n",
    "            self.flatten = nn.Flatten()\n",
    "            self.fc1 = nn.Linear(in_features=8, out_features=1000)\n",
    "            self.dropout1 = nn.Dropout(p=0.5)\n",
    "            self.fc2 = nn.Linear(1000, 500)\n",
    "            self.dropout2 = nn.Dropout(p=0.2)\n",
    "            self.fc3 = nn.Linear(500, 500)\n",
    "            self.dropout3 = nn.Dropout(p=0.5)\n",
    "            self.fc4 = nn.Linear(500, 500)\n",
    "            self.dropout4 = nn.Dropout(p=0.7)\n",
    "            self.fc5 = nn.Linear(500, 500)\n",
    "            self.dropout5 = nn.Dropout(p=0.2)\n",
    "            self.fc6 = nn.Linear(500, 500)\n",
    "            self.dropout6 = nn.Dropout(p=0.5)\n",
    "            self.fc7 = nn.Linear(500, 1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            print(f\"Input shape: {x.shape}\")\n",
    "            x = self.flatten(x)\n",
    "            print(f\"Flattened shape: {x.shape}\")\n",
    "            x = self.fc1(x)\n",
    "            x = self.dropout1(x)\n",
    "            x = F.leaky_relu(self.fc2(x))\n",
    "            x = self.dropout2(x)\n",
    "            x = F.leaky_relu(self.fc3(x))\n",
    "            x = self.dropout3(x)\n",
    "            x = F.leaky_relu(self.fc4(x))\n",
    "            x = self.dropout4(x)\n",
    "            x = F.leaky_relu(self.fc5(x))\n",
    "            x = self.dropout5(x)\n",
    "            x = F.leaky_relu(self.fc6(x))\n",
    "            x = self.dropout6(x)\n",
    "            x = torch.sigmoid(self.fc7(x))\n",
    "            return x\n",
    "    train_dataloader, test_dataloader, validation_dataloader = prepare_data(games_df)\n",
    "    class_weights = [1.0, 1.0]  # Adjust based on your dataset\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([class_weights[1]]))\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "\n",
    "    # Initialize early stopping\n",
    "    early_stopping = EarlyStopping(patience=10, min_delta=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \"min\", cooldown=5, patience=2\n",
    "    )\n",
    "\n",
    "    train_model(\n",
    "        model,\n",
    "        train_dataloader,\n",
    "        test_dataloader,\n",
    "        validation_dataloader,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        EarlyStopping(),\n",
    "        num_epochs=200,\n",
    "    )\n",
    "else:\n",
    "    print(\"Cell skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a rough outline of the final recommender system that I will be building in this notebook. It takes in the schedule for upcoming games, and outputs the recommended games that will be the closest and most exciting to watch based on the historical data from NBA games."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import NearestNeighbors\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# # Load the trained model\n",
    "# model = NearestNeighbors(n_neighbors=5, metric='cosine')\n",
    "# model.load('nba_game_recommender.pkl')\n",
    "\n",
    "# # Load the schedule for the upcoming night's games\n",
    "# schedule = pd.read_csv('nba_schedule.csv')\n",
    "\n",
    "# # Extract relevant features for each game\n",
    "# features = []\n",
    "# for index, row in schedule.iterrows():\n",
    "#     game_id = row['Game_ID']\n",
    "#     home_team = row['Home_Team']\n",
    "#     away_team = row['Away_Team']\n",
    "#     # Extract features from historical data\n",
    "#     feature_vector = get_features(game_id, home_team, away_team)\n",
    "#     features.append(feature_vector)\n",
    "\n",
    "# # Use the model to predict the most exciting game(s) to watch\n",
    "# distances, indices = model.kneighbors(features)\n",
    "# recommended_games = []\n",
    "# for i, dist in enumerate(distances):\n",
    "#     if dist < 0.5:  # Arbitrarily set a threshold"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
