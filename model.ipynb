{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "\n",
    "# change the display width to see all columns\n",
    "pd.set_option('display.width', 500)\n",
    "\n",
    "games_df = pd.read_csv('./data/games.csv', low_memory=False)\n",
    "games_details_df = pd.read_csv('./data/games_details.csv', low_memory=False)\n",
    "# players_df = pd.read_csv('./data/players.csv')\n",
    "ranking_df = pd.read_csv('./data/ranking.csv')\n",
    "teams_df = pd.read_csv('./data/teams.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the game dataframe and group by season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      GAME_DATE_EST   GAME_ID  HOME_TEAM_ID  VISITOR_TEAM_ID  SEASON  TEAM_ID_home  PTS_home  FG_PCT_home  FT_PCT_home  FG3_PCT_home  AST_home  REB_home  TEAM_ID_away  PTS_away  FG_PCT_away  FT_PCT_away  FG3_PCT_away  AST_away  REB_away  HOME_TEAM_WINS\n",
      "19288    2003-10-05  10300001    1610612762       1610612742    2003    1610612762      90.0        0.457        0.735         0.143      23.0      41.0    1610612742      85.0        0.447        0.500         0.250      20.0      38.0               1\n",
      "19287    2003-10-06  10300002    1610612763       1610612749    2003    1610612763     105.0        0.494        0.618         0.267      25.0      48.0    1610612749      94.0        0.427        0.700         0.154      20.0      43.0               1\n",
      "19280    2003-10-07  10300010    1610612764       1610612752    2003    1610612764     104.0        0.506        0.677         0.455      26.0      45.0    1610612752      86.0        0.380        0.852         0.188      19.0      37.0               1\n",
      "19286    2003-10-07  10300009    1610612758       1610612746    2003    1610612758     101.0        0.467        0.871         0.444      19.0      39.0    1610612746      82.0        0.368        0.609         0.364      13.0      50.0               1\n",
      "19285    2003-10-07  10300005    1610612757       1610612745    2003    1610612757     104.0        0.527        0.657         0.429      22.0      33.0    1610612745      80.0        0.470        0.667         0.333      10.0      37.0               1\n",
      "...             ...       ...           ...              ...     ...           ...       ...          ...          ...           ...       ...       ...           ...       ...          ...          ...           ...       ...       ...             ...\n",
      "19093    2003-11-08  20300081    1610612745       1610612753    2003    1610612745      96.0        0.450        0.682         0.409      21.0      51.0    1610612753      86.0        0.405        0.750         0.444      19.0      35.0               1\n",
      "19092    2003-11-08  20300078    1610612739       1610612764    2003    1610612739     111.0        0.524        0.677         0.250      30.0      42.0    1610612764      98.0        0.449        0.667         0.250      22.0      38.0               1\n",
      "19091    2003-11-08  20300082    1610612759       1610612742    2003    1610612759      78.0        0.325        0.808         0.188      15.0      49.0    1610612742      81.0        0.400        0.533         0.250      18.0      45.0               0\n",
      "19086    2003-11-09  20300088    1610612765       1610612751    2003    1610612765      98.0        0.438        0.758         0.300      25.0      41.0    1610612751      84.0        0.432        0.750         0.222      25.0      37.0               1\n",
      "19088    2003-11-09  20300085    1610612761       1610612743    2003    1610612761      89.0        0.487        0.769         0.385      25.0      41.0    1610612743      76.0        0.347        0.846         0.286      11.0      39.0               1\n",
      "\n",
      "[200 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "games_df = games_df.drop(columns=['GAME_STATUS_TEXT'])\n",
    "\n",
    "games_df.groupby(['SEASON'])\n",
    "games_df = games_df.sort_values('GAME_DATE_EST')\n",
    "\n",
    "# games_df = games_df.dropna()\n",
    "\n",
    "print(games_df.head(200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will create the ELO rating for each team, as a default the team will start with 1500 points. Each time a team wins or loses a game, the ELO rating will be updated. The ELO rating will be updated based on the following formula:\n",
    "\n",
    "\n",
    "\n",
    "Updated Team ELO = Team ELO + k * (Team Expected Outcome - Team Actual Outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_elo = 1500\n",
    "k_factor = 15\n",
    "team_elos = {team_id: initial_elo for team_id in pd.concat([games_df['HOME_TEAM_ID'], games_df['VISITOR_TEAM_ID']]).unique()}\n",
    "\n",
    "\n",
    "def expected_outcome(home_elo, away_elo):\n",
    "    return 1 / (1 + 10 ** ((away_elo - home_elo) / 400))\n",
    "\n",
    "def update_elo(home_elo, visitor_elo, home_win, k_factor):\n",
    "    expected_home_win = expected_outcome(home_elo, visitor_elo)\n",
    "    actual_home_win = 1 if home_win else 0\n",
    "    new_home_elo = home_elo + k_factor * (actual_home_win - expected_home_win)\n",
    "    new_visitor_elo = visitor_elo + k_factor * ((1 - actual_home_win) - (1 - expected_home_win))\n",
    "\n",
    "    return new_home_elo, new_visitor_elo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After iterating, team_elos will have the updated Elo ratings for each team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df = games_df.sort_values('GAME_DATE_EST', ascending=False)\n",
    "games_df['ELO_home'] = 0\n",
    "games_df['ELO_away'] = 0\n",
    "\n",
    "for index, row in games_df.iterrows():\n",
    "    home_team, away_team = row['HOME_TEAM_ID'], row['VISITOR_TEAM_ID']\n",
    "    home_elo, away_elo = team_elos[home_team], team_elos[away_team]\n",
    "    home_win = row['HOME_TEAM_WINS']\n",
    "    new_home_elo, new_away_elo = update_elo(home_elo, away_elo, home_win, k_factor)\n",
    "    games_df.at[index, 'ELO_home'] = round(new_home_elo)\n",
    "    games_df.at[index, 'ELO_away'] = round(new_away_elo)\n",
    "    \n",
    "    team_elos[home_team], team_elos[away_team] = new_home_elo, new_away_elo\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group each Season into its own dataframe, this will help for calculating the overall ELO rating for each team in a season. I can then also track the ELO rating for each team over time, and see how it changes over the course of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAME_DATE_EST      0.000000\n",
      "GAME_ID            0.000000\n",
      "HOME_TEAM_ID       0.000000\n",
      "VISITOR_TEAM_ID    0.000000\n",
      "SEASON             0.000000\n",
      "TEAM_ID_home       0.000000\n",
      "PTS_home           7.148014\n",
      "FG_PCT_home        7.148014\n",
      "FT_PCT_home        7.148014\n",
      "FG3_PCT_home       7.148014\n",
      "AST_home           7.148014\n",
      "REB_home           7.148014\n",
      "TEAM_ID_away       0.000000\n",
      "PTS_away           7.148014\n",
      "FG_PCT_away        7.148014\n",
      "FT_PCT_away        7.148014\n",
      "FG3_PCT_away       7.148014\n",
      "AST_away           7.148014\n",
      "REB_away           7.148014\n",
      "HOME_TEAM_WINS     0.000000\n",
      "ELO_home           0.000000\n",
      "ELO_away           0.000000\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n",
      "GAME_DATE_EST      0.0\n",
      "GAME_ID            0.0\n",
      "HOME_TEAM_ID       0.0\n",
      "VISITOR_TEAM_ID    0.0\n",
      "SEASON             0.0\n",
      "TEAM_ID_home       0.0\n",
      "PTS_home           0.0\n",
      "FG_PCT_home        0.0\n",
      "FT_PCT_home        0.0\n",
      "FG3_PCT_home       0.0\n",
      "AST_home           0.0\n",
      "REB_home           0.0\n",
      "TEAM_ID_away       0.0\n",
      "PTS_away           0.0\n",
      "FG_PCT_away        0.0\n",
      "FT_PCT_away        0.0\n",
      "FG3_PCT_away       0.0\n",
      "AST_away           0.0\n",
      "REB_away           0.0\n",
      "HOME_TEAM_WINS     0.0\n",
      "ELO_home           0.0\n",
      "ELO_away           0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "seasons_df = games_df.groupby('SEASON')\n",
    "seasons_dict = {}\n",
    "for season, season_df in seasons_df:\n",
    "    seasons_dict[season] = season_df\n",
    "\n",
    "# Iterate over the dictionary and calculate the percentage of missing values\n",
    "for season, season_df in seasons_dict.items():\n",
    "    missing_values_percent = season_df.isnull().sum() * 100 / len(season_df)\n",
    "    # print(f\"Percentage of missing values for season {season}:\")\n",
    "    print(missing_values_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here each team's ELO will be saved in a dataframe then merged with the team dataframe to get the ELO rating for each team in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_elos_df = pd.DataFrame.from_dict(team_elos, orient=\"index\", columns=[\"ELO\"])\n",
    "team_elos_df = team_elos_df.merge(teams_df, left_index=True, right_on=\"TEAM_ID\")\n",
    "team_elos_df = team_elos_df.sort_values(\"ELO\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of close games: 5631\n",
      "Probability of a close game: 21.20744200060259\n"
     ]
    }
   ],
   "source": [
    "# Create margin of victory column\n",
    "games_df[\"MOV\"] = games_df[\"PTS_home\"] - games_df[\"PTS_away\"]\n",
    "close_games = games_df[(games_df[\"MOV\"] > -5) & (games_df[\"MOV\"] < 5)]\n",
    "print(\"Number of close games:\", close_games.shape[0])\n",
    "\n",
    "close_game_prob = close_games[\"MOV\"].count() / games_df[\"MOV\"].count() * 100\n",
    "print(\"Probability of a close game:\", close_game_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of high scoring games: 6258\n",
      "Probability of a high scoring game: 23.48129526096582\n"
     ]
    }
   ],
   "source": [
    "# Create high scoring game column\n",
    "games_df[\"total_score\"] = games_df[\"PTS_home\"] + games_df[\"PTS_away\"]\n",
    "high_scoring_games = games_df[games_df[\"total_score\"] > 220]\n",
    "print(\"Number of high scoring games:\", high_scoring_games.shape[0])\n",
    "\n",
    "high_scoring_game_prob = len(high_scoring_games) / len(games_df) * 100\n",
    "print(\"Probability of a high scoring game:\", high_scoring_game_prob)\n",
    "\n",
    "games_df = games_df.dropna(ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model each time the model is trained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, losses):\n",
    "    average_loss = round(np.average(losses), 3)\n",
    "    model_to_string = model.__class__.__name__\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    if not os.path.exists(f'./models/{model_to_string}'):\n",
    "        os.makedirs(f'./models/{model_to_string}')\n",
    "    torch.save(model.state_dict(), f=f'./models/{model_to_string}/{average_loss}_on_{timestamp}_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(targets, predictions):\n",
    "    predictions_binary = [1 if pred > 0.5 else 0 for pred in predictions]\n",
    "    accuracy = accuracy_score(targets, predictions_binary)\n",
    "    precision = precision_score(targets, predictions_binary, zero_division=0.0)\n",
    "    recall = recall_score(targets, predictions_binary)\n",
    "    f1 = f1_score(targets, predictions_binary)\n",
    "    roc_auc = roc_auc_score(targets, predictions)\n",
    "    conf_matrix = confusion_matrix(targets, predictions_binary)\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"conf_matrix\": conf_matrix\n",
    "    }\n",
    "\n",
    "def print_metrics(phase, metrics):\n",
    "    print(f\"{phase} Accuracy: {metrics['accuracy']}\")\n",
    "    print(f\"{phase} Precision: {metrics['precision']}\")\n",
    "    print(f\"{phase} Recall: {metrics['recall']}\")\n",
    "    print(f\"{phase} F1-Score: {metrics['f1']}\")\n",
    "    print(f\"{phase} ROC-AUC: {metrics['roc_auc']}\")\n",
    "    print(f\"{phase} Confusion Matrix:\\n{metrics['conf_matrix']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class will stop training runs if the training loss is not decreasing anymore. This is done through comparing the current loss with the previous loss. If the loss is not decreasing, the training will stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training function, this function will train the model on the training data and return the model. The model will be trained using the training data and the labels. The model will be trained for a certain number of epochs and the loss will be calculated after each epoch. The loss will be used to determine if the model is improving or not. If the loss is not decreasing, the training will stop.\n",
    "\n",
    "Calculating and printing the metrics for the model, we will use the following metrics: accuracy, precision, recall, f1 score, and confusion matrix. These metrics will help us understand how well the model is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, test_dataloader, criterion, optimizer, early_stopping, num_epochs=100):\n",
    "    criterion = nn.BCELoss(weight=torch.tensor(0.75))\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', cooldown=5, patience=2)\n",
    "    early_stopping = EarlyStopping(patience=10, min_delta=0.001)\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_targets = []\n",
    "        train_predictions = []\n",
    "\n",
    "        for inputs, targets in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.squeeze()\n",
    "            loss = criterion(outputs, targets.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step(loss)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            train_targets.extend(targets.numpy())\n",
    "            train_predictions.extend(outputs.detach().numpy())\n",
    "\n",
    "        train_metrics = calculate_metrics(train_targets, train_predictions)\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "            print_metrics(\"Train\", train_metrics)\n",
    "\n",
    "        model.eval()\n",
    "        val_targets = []\n",
    "        val_predictions = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_dataloader:\n",
    "                outputs = model(inputs)\n",
    "                outputs = outputs.squeeze()\n",
    "                val_targets.extend(targets.numpy())\n",
    "                val_predictions.extend(outputs.numpy())\n",
    "\n",
    "        val_metrics = calculate_metrics(val_targets, val_predictions)\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print_metrics(\"Validation\", val_metrics)\n",
    "\n",
    "        val_loss = criterion(torch.tensor(val_predictions), torch.tensor(val_targets).float()).item()\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            break\n",
    "        \n",
    "    save_model(model, losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing function, this function will preprocess the data before training the model. The data will be split into training and testing data. The data will be normalized and the labels will be one-hot encoded. The data will be split into training and testing data using the train_test_split function from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(games_df):\n",
    "    features_df = games_df[\n",
    "            [\n",
    "                # \"PTS_home\",\n",
    "                # \"PTS_away\",\n",
    "                # \"FG_PCT_home\",\n",
    "                # \"FT_PCT_home\",\n",
    "                # \"FG3_PCT_home\",\n",
    "                # \"AST_home\",\n",
    "                # \"REB_home\",\n",
    "                # \"FG_PCT_away\",\n",
    "                # \"FT_PCT_away\",\n",
    "                # \"FG3_PCT_away\",\n",
    "                # \"AST_away\",\n",
    "                # \"REB_away\",\n",
    "                \"SEASON\",\n",
    "                # \"MOV\",\n",
    "                \"total_score\",\n",
    "                \"ELO_home\",\n",
    "                \"ELO_away\",\n",
    "                \"HOME_TEAM_ID\",\n",
    "                \"VISITOR_TEAM_ID\",]\n",
    "    ]\n",
    "    features = torch.tensor(features_df.values, dtype=torch.float32)\n",
    "    labels = torch.tensor(games_df[\"HOME_TEAM_WINS\"])\n",
    "\n",
    "    dataset = TensorDataset(features, labels)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=128)\n",
    "\n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Model Creation\n",
    "\n",
    "The model is created, experimenting with the different model architecture. The model will be trained on the first 80% of the data, and tested on the last 20% of the data. The model will be evaluated based on the accuracy of the predictions. \n",
    "\n",
    "The model will be trained on the ELO rating of each team, and the difference in ELO rating between the two teams. The model will predict the outcome of the game based on the ELO rating of each team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 47.619049072265625\n",
      "Train Accuracy: 0.40425531914893614\n",
      "Train Precision: 0.0\n",
      "Train Recall: 0.0\n",
      "Train F1-Score: 0.0\n",
      "Train ROC-AUC: 0.5\n",
      "Train Confusion Matrix:\n",
      "[[2147    0]\n",
      " [3164    0]]\n",
      "Validation Accuracy: 0.41240996186620216\n",
      "Validation Precision: 0.0\n",
      "Validation Recall: 0.0\n",
      "Validation F1-Score: 0.0\n",
      "Validation ROC-AUC: 0.5\n",
      "Validation Confusion Matrix:\n",
      "[[ 8760     0]\n",
      " [12481     0]]\n",
      "Epoch 10, Loss: 47.619049072265625\n",
      "Train Accuracy: 0.40425531914893614\n",
      "Train Precision: 0.0\n",
      "Train Recall: 0.0\n",
      "Train F1-Score: 0.0\n",
      "Train ROC-AUC: 0.5\n",
      "Train Confusion Matrix:\n",
      "[[2147    0]\n",
      " [3164    0]]\n",
      "Validation Accuracy: 0.41240996186620216\n",
      "Validation Precision: 0.0\n",
      "Validation Recall: 0.0\n",
      "Validation F1-Score: 0.0\n",
      "Validation ROC-AUC: 0.5\n",
      "Validation Confusion Matrix:\n",
      "[[ 8760     0]\n",
      " [12481     0]]\n",
      "Early stopping at epoch 11\n"
     ]
    }
   ],
   "source": [
    "skip_cell = True\n",
    "\n",
    "if not skip_cell:\n",
    "    class BinaryClassifier(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(BinaryClassifier, self).__init__()\n",
    "            self.fc1 = nn.Linear(in_features=6, out_features=50)\n",
    "            self.fc2 = nn.Linear(50, 1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.prelu(self.fc1(x), torch.tensor(0.75))\n",
    "            x = torch.sigmoid(self.fc2(x))\n",
    "            return x\n",
    "    \n",
    "    test_dataloader, train_dataloader = prepare_data(games_df)\n",
    "    model = BinaryClassifier()\n",
    "    criterion = nn.BCELoss(weight=torch.tensor(0.75))\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    \n",
    "    train_model(model, train_dataloader, test_dataloader, criterion, optimizer, EarlyStopping, num_epochs=100)\n",
    "else: \n",
    "    print(\"Cell skipped\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model v2 - relu activation function and larger hidden layers\n",
    "Here I have created a model with larger hidden layers, and more hidden layers, to see if the model can learn more complex patterns in the data. The learning rate is lowered and a scheduler is added to help the model converge to a better solution. The model is trained for 100 epochs, and the loss rate is assessed to see if the model is learning at a better rate than the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell skipped\n"
     ]
    }
   ],
   "source": [
    "skip_cell = True\n",
    "if not skip_cell:\n",
    "    class BinaryClassifierV2(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(BinaryClassifierV2, self).__init__()\n",
    "            self.fc1 = nn.Linear(in_features=6, out_features=1000)\n",
    "            self.fc2 = nn.Linear(1000, 50)\n",
    "            self.fc3 = nn.Linear(50, 1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = torch.sigmoid(self.fc3(x))\n",
    "            return x\n",
    "\n",
    "    model = BinaryClassifierV2()\n",
    "    criterion = nn.BCELoss(weight=torch.tensor(0.75))\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', cooldown=5, patience=2)\n",
    "\n",
    "    train_model(model, train_dataloader, test_dataloader, criterion, optimizer, EarlyStopping, num_epochs=10)\n",
    "else: \n",
    "    print(\"Cell skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model v3.1 - More model information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell skipped\n"
     ]
    }
   ],
   "source": [
    "skip_cell = True\n",
    "if not skip_cell:\n",
    "    class BinaryClassifierV3(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(BinaryClassifierV3, self).__init__()\n",
    "            self.fc1 = nn.Linear(in_features=6, out_features=1000)\n",
    "            self.fc2 = nn.Linear(1000, 50)\n",
    "            self.fc3 = nn.Linear(50, 1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = torch.sigmoid(self.fc3(x))\n",
    "            return x\n",
    "\n",
    "\n",
    "    model = BinaryClassifierV3()\n",
    "    criterion = nn.BCELoss(weight=torch.tensor(0.75))\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', cooldown=5, patience=2)\n",
    "\n",
    "    train_model(model, train_dataloader, test_dataloader, criterion, optimizer, EarlyStopping, num_epochs=25)\n",
    "\n",
    "else:\n",
    "    print(\"Cell skipped\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Model - Adding Dropout Layers\n",
    "\n",
    "Here I have added dropout layers to the model to help prevent overfitting. The dropout rate is set to 0.5, increasing layer count to 7 and increasing the number of neurons in each layer. The model is evaluated based on the loss rate, and the accuracy of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 41.66666793823242\n",
      "Train Accuracy: 0.4541517604970815\n",
      "Train Precision: 0.6015325670498084\n",
      "Train Recall: 0.24810366624525917\n",
      "Train F1-Score: 0.3513090176773328\n",
      "Train ROC-AUC: 0.5029526249251447\n",
      "Train Confusion Matrix:\n",
      "[[1627  520]\n",
      " [2379  785]]\n",
      "Validation Accuracy: 0.41240996186620216\n",
      "Validation Precision: 0.0\n",
      "Validation Recall: 0.0\n",
      "Validation F1-Score: 0.0\n",
      "Validation ROC-AUC: 0.5\n",
      "Validation Confusion Matrix:\n",
      "[[ 8760     0]\n",
      " [12481     0]]\n",
      "Epoch 10, Loss: 39.28571319580078\n",
      "Train Accuracy: 0.44417247222745243\n",
      "Train Precision: 0.5814132104454686\n",
      "Train Recall: 0.23925410872313527\n",
      "Train F1-Score: 0.3390058217644425\n",
      "Train ROC-AUC: 0.492705768846896\n",
      "Train Confusion Matrix:\n",
      "[[1602  545]\n",
      " [2407  757]]\n",
      "Validation Accuracy: 0.41240996186620216\n",
      "Validation Precision: 0.0\n",
      "Validation Recall: 0.0\n",
      "Validation F1-Score: 0.0\n",
      "Validation ROC-AUC: 0.5\n",
      "Validation Confusion Matrix:\n",
      "[[ 8760     0]\n",
      " [12481     0]]\n",
      "Early stopping at epoch 11\n"
     ]
    }
   ],
   "source": [
    "skip_cell = False\n",
    "if not skip_cell:\n",
    "    # Calculate class weights\n",
    "    class_counts = games_df[\"HOME_TEAM_WINS\"].value_counts()\n",
    "    class_weights = 1. / class_counts\n",
    "    sample_weights = class_weights[games_df[\"HOME_TEAM_WINS\"]]\n",
    "\n",
    "    # Use weighted loss function\n",
    "\n",
    "    class BinaryClassifierDropout(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(BinaryClassifierDropout, self).__init__()\n",
    "            self.fc1 = nn.Linear(in_features=6, out_features=1000)\n",
    "            self.dropout1 = nn.Dropout(p=0.5)\n",
    "            self.fc2 = nn.Linear(1000, 1000)\n",
    "            self.dropout2 = nn.Dropout(p=0.5)\n",
    "            self.fc3 = nn.Linear(1000, 1000)\n",
    "            self.dropout3 = nn.Dropout(p=0.5)\n",
    "            self.fc4 = nn.Linear(1000, 1000)\n",
    "            self.dropout4 = nn.Dropout(p=0.5)\n",
    "            self.fc5 = nn.Linear(1000, 1000)\n",
    "            self.dropout5 = nn.Dropout(p=0.5)\n",
    "            self.fc6 = nn.Linear(1000, 500)\n",
    "            self.dropout6 = nn.Dropout(p=0.5)\n",
    "            self.fc7 = nn.Linear(500, 1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = self.dropout1(x)\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.dropout2(x)\n",
    "            x = F.relu(self.fc3(x))\n",
    "            x = self.dropout3(x)\n",
    "            x = F.relu(self.fc4(x))\n",
    "            x = self.dropout4(x)\n",
    "            x = F.relu(self.fc5(x))\n",
    "            x = self.dropout5(x)\n",
    "            x = F.relu(self.fc6(x))\n",
    "            x = self.dropout6(x)\n",
    "            x = torch.sigmoid(self.fc7(x))\n",
    "            return x\n",
    "\n",
    "    model = BinaryClassifierDropout()\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([class_weights[1]]))\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', cooldown=5, patience=2)\n",
    "\n",
    "    train_model(model, train_dataloader, test_dataloader, criterion, optimizer, EarlyStopping, num_epochs=20)\n",
    "else:\n",
    "    print(\"Cell skipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a rough outline of the final recommender system that I will be building in this notebook. It takes in the schedule for upcoming games, and outputs the recommended games that will be the closest and most exciting to watch based on the historical data from NBA games."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import NearestNeighbors\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# # Load the trained model\n",
    "# model = NearestNeighbors(n_neighbors=5, metric='cosine')\n",
    "# model.load('nba_game_recommender.pkl')\n",
    "\n",
    "# # Load the schedule for the upcoming night's games\n",
    "# schedule = pd.read_csv('nba_schedule.csv')\n",
    "\n",
    "# # Extract relevant features for each game\n",
    "# features = []\n",
    "# for index, row in schedule.iterrows():\n",
    "#     game_id = row['Game_ID']\n",
    "#     home_team = row['Home_Team']\n",
    "#     away_team = row['Away_Team']\n",
    "#     # Extract features from historical data\n",
    "#     feature_vector = get_features(game_id, home_team, away_team)\n",
    "#     features.append(feature_vector)\n",
    "\n",
    "# # Use the model to predict the most exciting game(s) to watch\n",
    "# distances, indices = model.kneighbors(features)\n",
    "# recommended_games = []\n",
    "# for i, dist in enumerate(distances):\n",
    "#     if dist < 0.5:  # Arbitrarily set a threshold"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
